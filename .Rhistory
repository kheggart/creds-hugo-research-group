c <- list(c[[1]][c[[1]] != ""])
list.members <- c(list.members, c)
#remove the 5th element
list.members <- list.members[1:4]
list.members
positions <- c(grep("(<h4>)\\w+",unlist(list.members[2])),length(unlist(list.members[2]))) #where are the H4s for this group, and what's the final position in the document (end point for last person's anchor)
members <- unlist(list.members[2])
map2(positions[1:length(positions)-1],positions[2:length(positions)], extract) #function to extract
#And extract just the relevant chunk for this member
raw <- members[x:y]
raw
#Grab the picture if there is one
pic <- ifelse(grepl("img",members[x]),members[x],paste0("no pic"))
#Find the p bio, and grab that
index <- grep("<p>",raw)
bio <- c(raw[c(index)])
bio <- paste(bio, collapse="\n")
bio <- html_text(read_html(bio))
short_bio <- str_extract(bio, '.*?[a-z0-9][.?!](?= )')
pic
bio
#Find the bit with the links in it
ifelse(grepl("<ul>",raw), {
index <- head(grep("<ul>",raw),1) #grab the first place it occurs
index_end <- ifelse(length(grep("</ul>",raw))<index,length(raw),tail(grep("</ul>",raw))) #grab the last place it occurs
links <- ifelse(length(index)>0,c(raw[c(index:index_end)]),"")
index <- grep("<a href", links)  #ifelse(length(links)>0,grep("<a href", links), "")
links <- ifelse(length(index)<1, "",
read_html(unlist(links[[index]])) %>%
html_nodes("a") %>%
html_attr("href")
)
},
links <- paste0(" "))
#Find the UTS profile, href for UTS
index <- grep("uts.edu.au",links)
profile <- ifelse(length(index)<1,paste0(""),links[c(index)])
#Find the twitter handle, href for twitter
index <- grep("twitter",links)
twitter <- ifelse(length(index)<1,paste0(""),links[c(index)])
#and then return all of that...this is VERY inelegant but it should work
person <- as.data.frame(cbind(group,name,pic,bio,short_bio,profile,twitter))
#############FOR ASSOCIATES ################
positions <- c(grep("(<h4>)\\w+",unlist(list.members[2])),length(unlist(list.members[2]))) #where are the H4s for this group, and what's the final position in the document (end point for last person's anchor)
positions
members <- unlist(list.members[2])
map2(positions[1:length(positions)-1],positions[2:length(positions)], extract) #function to extract
##############HONORARIES #################
positions <- c(grep("(<h4>)\\w+",unlist(list.members[3])),length(unlist(list.members[3]))) #where are the H4s for this group, and what's the final position in the document (end point for last person's anchor)
members <- unlist(list.members[3])
map2(positions[1:length(positions)-1],positions[2:length(positions)], extract) #function to extract
overall$group <- c(rep(" associate member",length(grep("(<h4>)\\w+",unlist(list.members[3]))))) #add member group for n of people in it
#Create a dataframe
overall <- data.frame(group=character(),
name=character(),
pic=character(),
bio=character(),
short_bio=character(),
profile=character(),
twitter=character(),
stringsAsFactors=FALSE)
###########FOR THE MEMBERS ###########
positions <- c(grep("(<h4>)\\w+",unlist(list.members[1])),length(unlist(list.members[1]))) #where are the H4s for this group, and what's the final position in the document (end point for last person's anchor)
members <- unlist(list.members[1])
map2(positions[1:length(positions)-1],positions[2:length(positions)], extract) #function to extract
overall$group <- c(rep("member",length(grep("(<h4>)\\w+",unlist(list.members[1]))))) #add member group for n of people in it
##############HONORARIES #################
positions <- c(grep("(<h4>)\\w+",unlist(list.members[3])),length(unlist(list.members[3]))) #where are the H4s for this group, and what's the final position in the document (end point for last person's anchor)
members <- unlist(list.members[3])
map2(positions[1:length(positions)-1],positions[2:length(positions)], extract) #function to extract
overall$group <- c(overall$group,rep("honorary associate member",length(grep("(<h4>)\\w+",unlist(list.members[3]))))) #add member group for n of people in it
overall$group
overall$group <- str_replace_all(overall$group, "blank", "honorary associate member")
overall$group
############### HDRS #######################
positions <- c(grep("(<h4>)\\w+",unlist(list.members[4])),length(unlist(list.members[4]))) #where are the H4s for this group, and what's the final position in the document (end point for last person's anchor)
members <- unlist(list.members[4])
map2(positions[1:length(positions)-1],positions[2:length(positions)], extract) #function to extract
overall$group <- str_replace_all(overall$group, "blank", "Higher Degree Research Student")
#############FOR ASSOCIATES ################
positions <- c(grep("(<h4>)\\w+",unlist(list.members[2])),length(unlist(list.members[2]))) #where are the H4s for this group, and what's the final position in the document (end point for last person's anchor)
#Create a dataframe
overall <- data.frame(group=character(),
name=character(),
pic=character(),
bio=character(),
short_bio=character(),
profile=character(),
twitter=character(),
stringsAsFactors=FALSE)
#This function is hideous but it works
extract <- function(x,y) {
#x <- positions[8] #for testing
#y <- positions[6] #for testing
#counter <- x-5
#add membership group
group <- "blank"
#Add their name
name <- str_replace_all(members[x],c("<h4>" = "", "</h4>" = ""))
#Then set the position to one back from the heading, and to 2 back from the NEXT heading
x <- x-1
#Grab the picture if there is one
pic <- ifelse(grepl("img",members[x]),members[x],paste0("no pic"))
#y <- ifelse(y-x < 3, y, y-2)  #This matters only if there if there is a
#And extract just the relevant chunk for this member
raw <- members[x:y]
#Find the p bio, and grab that
index <- grep("<p>",raw)
bio <- c(raw[c(index)])
bio <- paste(bio, collapse="\n")
bio <- html_text(read_html(bio))
short_bio <- str_extract(bio, '.*?[a-z0-9][.?!](?= )')
#Find the bit with the links in it
ifelse(grepl("<ul>",raw), {
index <- head(grep("<ul>",raw),1) #grab the first place it occurs
index_end <- ifelse(length(grep("</ul>",raw))<index,length(raw),tail(grep("</ul>",raw))) #grab the last place it occurs
links <- ifelse(length(index)>0,c(raw[c(index:index_end)]),"")
index <- grep("<a href", links)  #ifelse(length(links)>0,grep("<a href", links), "")
links <- ifelse(length(index)<1, "",
read_html(unlist(links[[index]])) %>%
html_nodes("a") %>%
html_attr("href")
)
},
links <- paste0(" "))
#Find the UTS profile, href for UTS
index <- grep("uts.edu.au",links)
profile <- ifelse(length(index)<1,paste0(""),links[c(index)])
#Find the twitter handle, href for twitter
index <- grep("twitter",links)
twitter <- ifelse(length(index)<1,paste0(""),links[c(index)])
#and then return all of that...this is VERY inelegant but it should work
person <- as.data.frame(cbind(group,name,pic,bio,short_bio,profile,twitter))
person %>%
mutate(across(everything(), as.character))
overall <<- rbind(overall,person)
}
###########FOR THE MEMBERS ###########
positions <- c(grep("(<h4>)\\w+",unlist(list.members[1])),length(unlist(list.members[1]))) #where are the H4s for this group, and what's the final position in the document (end point for last person's anchor)
members <- unlist(list.members[1])
map2(positions[1:length(positions)-1],positions[2:length(positions)], extract) #function to extract
overall$group <- c(rep("member",length(grep("(<h4>)\\w+",unlist(list.members[1]))))) #add member group for n of people in it
##############HONORARIES #################
positions <- c(grep("(<h4>)\\w+",unlist(list.members[3])),length(unlist(list.members[3]))) #where are the H4s for this group, and what's the final position in the document (end point for last person's anchor)
members <- unlist(list.members[3])
map2(positions[1:length(positions)-1],positions[2:length(positions)], extract) #function to extract
overall$group <- str_replace_all(overall$group, "blank", "honorary associate member")
############### HDRS #######################
positions <- c(grep("(<h4>)\\w+",unlist(list.members[4])),length(unlist(list.members[4]))) #where are the H4s for this group, and what's the final position in the document (end point for last person's anchor)
members <- unlist(list.members[4])
map2(positions[1:length(positions)-1],positions[2:length(positions)], extract) #function to extract
overall1 <- overall1
overall1 <- overall
#############FOR ASSOCIATES ################
positions <- c(grep("(<h4>)\\w+",unlist(list.members[2])),length(unlist(list.members[2]))) #where are the H4s for this group, and what's the final position in the document (end point for last person's anchor)
members <- unlist(list.members[2])
map2(positions[1:length(positions)-1],positions[2:length(positions)], extract) #function to extract
overall$group <- str_replace_all(overall$group, "blank", "associate member")
rm(overall1)
overall$pic
overall$pic[20]
?html_element
html_elements(read_html(overall$pic[20]),"img src")
html_elements(read_html(overall$pic[20]),"picture")
as.character(html_elements(read_html(overall$pic[20]),"picture"))
html_elements(read_html(overall$pic[20]),"img")
html_elements(read_html(overall$pic[20]),"img") %>% html_attr("data-src")
html_elements(read_html(overall$pic[20]),"img") %>% html_attr("img-src")
html_elements(read_html(overall$pic[20]),"img") %>% html_attr("a")
html_elements(read_html(overall$pic[20]),"img") %>% html_attr("href")
read_html(overall$pic[20])) %>%
html_node(xpath = '//*/img') %>%
html_attr('src')
read_html(overall$pic[20]) %>%
html_node(xpath = '//*/img') %>%
html_attr('src')
overall$pic_url <- lapply(overall$pic, function(x) {
ifelse(grep("no pic", x, "no pic", {
read_html(x) %>%
html_node(xpath = '//*/img') %>%
html_attr('src')
}))
})
overall$pic_url <- lapply(overall$pic, function(x) {
ifelse(grepl("no pic", x), "no pic", {
read_html(x) %>%
html_node(xpath = '//*/img') %>%
html_attr('src')
})
})
head(overall)
?apply
colnames(overall)
overall["name"]
overall[1]
overall[,1]
overall[1,]
x <- overall[1,] #for testing
#x <- overall[1,] #for testing
ifelse(sapply(list.files("/content/authors", full.names=TRUE), FUN=function(x){
@
#x <- overall[1,] #for testing
ifelse(sapply(list.files("/content/authors", full.names=TRUE), FUN=function(x){
grepl(x["name"], readLines(x))
}),
paste0("yes"), paste0("no"))
sapply(list.files("/content/authors", full.names=TRUE), FUN=function(x){
grepl(x["name"], readLines(x))
})
sapply(list.files("/content/authors", full.names=TRUE), FUN=function(y){
grepl(x["name"], readLines(y))
})
sapply(list.files("/content/authors", full.names=TRUE), FUN=function(y){
grepl("Simon Knight", readLines(y))
})
?list.files
#x <- overall[1,] #for testing
ifelse(sapply(list.files("/content/authors", full.names=TRUE, recursive=TRUE), FUN=function(x){
grepl(x["name"], readLines(x))
}), paste0("yes"), paste0("no"))
sapply(list.files("/content/authors", full.names=TRUE, recursive=TRUE), FUN=function(x){
grepl(x["name"], readLines(x))
})
list.files("/content/authors",full.names=T,recursive=T)
getwd
getwd()
list.files("content/authors",full.names=T,recursive=T)
sapply(list.files("content/authors", full.names=TRUE, recursive=TRUE), FUN=function(x){
grepl(x["name"], readLines(x))
})
sapply(list.files("content/authors", full.names=TRUE, recursive=TRUE), FUN=function(x){
grepl("Simon Knight", readLines(x))
})
sapply(list.files("content/authors", full.names=TRUE, recursive=TRUE), FUN=function(y){
grepl("Simon Knight", readLines(y))
})
sapply(list.files("content/authors", full.names=TRUE, recursive=TRUE), FUN=function(y){
grep("Simon Knight", readLines(y))
})
sum(sapply(list.files("content/authors", full.names=TRUE, recursive=TRUE), FUN=function(y){
grepl("Simon Knight", readLines(y))
}))
sapply(list.files("content/authors", full.names=TRUE, recursive=TRUE), FUN=function(y){
grep("Simon Knight", readLines(y))
})
?list.files
list.files("content/authors", full.names=TRUE, recursive=TRUE, pattern="index.md")
colnames(overall)
#x <- overall[1,] #for testing
ifelse(sapply(list.files("content/authors", full.names=TRUE, recursive=TRUE, pattern="index.md"),
FUN=function(y){
grepl(x[2], readLines(y))
}),
paste0("yes"), paste0("no"))
sapply(list.files("content/authors", full.names=TRUE, recursive=TRUE, pattern="index.md"),
FUN=function(y){
grepl(x[2], readLines(y))
})
x[2]
x[[2]]
sapply(list.files("content/authors", full.names=TRUE, recursive=TRUE, pattern="index.md"),
FUN=function(y){
grep(x[[2]], readLines(y))
}),
paste0("yes"), paste0("no"))
sapply(list.files("content/authors", full.names=TRUE, recursive=TRUE, pattern="index.md"),
FUN=function(y){
grep(x[[2]], readLines(y))
})
list.files("content/authors", full.names=TRUE, recursive=TRUE, pattern="index.md")
grep("Simon Knight", readlines(c( "content/authors/admin/_index.md","content/authors/Simon-Knight/_index.md")))
grep("Simon Knight", readLines(c( "content/authors/admin/_index.md","content/authors/Simon-Knight/_index.md")))
fil <- list.files("content/authors", full.names=TRUE, recursive=TRUE, pattern="index.md")
sapply(fil, function(y) { grep("Simon Knight",readLines(y))})
paste0(sapply(fil, function(y) { grep("Simon Knight",readLines(y))}))
table(sapply(fil, function(y) { grepl("Simon Knight",readLines(y))}))
sapply(fil, function(y) { grepl("Simon Knight",readLines(y))})
sapply(fil, function(y) { any(grepl("Simon Knight",readLines(y))}))
sapply(fil, function(y) { any(grepl("Simon Knight",readLines(y)))})
any(sapply(fil, function(y) { any(grepl("Simon Knight",readLines(y)))}))
grep(x[[2]], readLines("content/authors/Simon-Knight/_index.md"))
grep("Simon Knight", readLines("content/authors/Simon-Knight/_index.md"))
grep(paste0(x[[2]]), readLines("content/authors/Simon-Knight/_index.md"))
grep(paste0(x[2]), readLines("content/authors/Simon-Knight/_index.md"))
grep(paste0(unlist(x[2])), readLines("content/authors/Simon-Knight/_index.md"))
grep((unlist(x[2])), readLines("content/authors/Simon-Knight/_index.md"))
grep((unlist(x[[2]])), readLines("content/authors/Simon-Knight/_index.md"))
x[2]
paste0(x[2])
x <- overall[2,] #for testing
grep("Simon Knight", readLines("content/authors/Simon-Knight/_index.md"))
grepl("Simon Knight", readLines("content/authors/Simon-Knight/_index.md"))
any(grepl("Simon Knight", readLines("content/authors/Simon-Knight/_index.md")))
x[2]
paste(x[2],sep="-")
?gsub
gsub(" ","-",paste(x[2]))
dir.create(paste0("content/authors/",gsub(" ","-",paste(x[2]))))
dir.create(paste0("content\\authors\\",gsub(" ","-",paste(x[2]))))
?create.dir
?dir.create
dir.create(paste0(".content\\authors\\",gsub(" ","-",paste(x[2]))))
gitcreds::getcreds_set()
gitcreds::gitcreds_set()
gitcreds::gitcreds_set()
install.packages("gitcreds")
library(gitcreds)
gitcreds_get()
gitcreds_set()
install.packages("aRtsy")
library(aRtsy)
devtools::install_github("cutterkom/generativeart")
# remotes::install_github("thomasp85/ambient")
remotes::install_github("djnavarro/jasmines")
devtools::install_github("djnavarro/jasmines")
library(aRtsy)
library(generativeart)
devtools::install_github("cutterkom/generativeart")
stringr::str_detect("a\"b", fixed("\""))
library(stringr)
stringr::str_detect("a\"b", fixed("\""))
?list.files
fileNames <- list.files(path = "content/publication", pattern = "*.md", full.names = T, recursive = T, ignore.case = T, include.dirs = T)
head(filenames)
head(fileNames)
fileNames <- list.files(path = "content/publication", pattern = ".md", full.names = T, recursive = T, ignore.case = T, include.dirs = T)
head(fileNames)
getwd()
fileNames <- list.files(path = "content/publication/", pattern = ".md", full.names = T, recursive = T, ignore.case = T, include.dirs = T)
head(fileNames)
fileNames <- list.files(path = "/content/publication/", pattern = ".md", full.names = T, recursive = T, ignore.case = T, include.dirs = T)
head(fileNames)
fileNames <- list.files(path = "./content/publication/", pattern = ".md", full.names = T, recursive = T, ignore.case = T, include.dirs = T)
head(fileNames)
fileNames <- list.files(path = "./content/publication/",  full.names = T, recursive = T, ignore.case = T, include.dirs = T)
head(fileNames)
fileNames <- list.files(path = "content/publication/",  full.names = T, recursive = T, ignore.case = T, include.dirs = T)
head(fileNames)
getwd()
fileNames <- list.files(path = "c:.Hugo/Sites/creds/content/publication/",  full.names = T, recursive = T, ignore.case = T, include.dirs = T)
head(fileNames)
fileNames <- list.files(path = "c:.Hugo/Sites/creds/content/publication/", pattern = ".md" full.names = T, recursive = T, ignore.case = T, include.dirs = T)
fileNames <- list.files(path = "c:.Hugo/Sites/creds/content/publication/", pattern = ".md", full.names = T, recursive = T, ignore.case = T, include.dirs = T)
head(fileNames)
fileNames <- list.files(path = "c:.Hugo/Sites/creds/content/publication/", pattern = "\\.md", full.names = T, recursive = T, ignore.case = T, include.dirs = T)
head(fileNames)
fileNames <- list.files(path = "c:/Hugo/Sites/creds/content/publication/", pattern = "\\.md", full.names = T, recursive = T, ignore.case = T, include.dirs = T)
head(fileNames)
stringr::str_detect(readlines("c:/Hugo/Sites/creds/content/publication//agarwal-identification-classification-cyberbullying-2020/index.md")
)
stringr::str_detect(readlines("c:/Hugo/Sites/creds/content/publication//agarwal-identification-classification-cyberbullying-2020/index.md"), fixed("\""))
?readLines
stringr::str_detect(readLines("c:/Hugo/Sites/creds/content/publication//agarwal-identification-classification-cyberbullying-2020/index.md"), fixed("\""))
stringr::str_detect(readLines("c:/Hugo/Sites/creds/content/publication//agarwal-identification-classification-cyberbullying-2020/index.md"), fixed("\\\\\""))
stringr::str_detect("\"", fixed("\\\\\""))
stringr::str_detect("\\\\\"", fixed("\\\\\""))
for (fileName in fileNames) {
if (length(stringr::str_detect(readLines(fileName), fixed("\\\\\""))) > 0) { print(fileName)}
}
?stringr
?str_detect
for (fileName in fileNames) {
if (length(stringr::str_which(readLines(fileName), fixed("\\\\\""))) > 0) { print(fileName)}
}
for (fileName in fileNames) {
if (length(stringr::str_which(readLines(fileName), fixed("M Coupland"))) > 0) { print(fileName)}
}
for (fileName in fileNames) {
if (length(stringr::str_which(readLines(fileName), fixed("M-Coupland"))) > 0) { print(fileName)}
}
for (fileName in fileNames) {
if (length(stringr::str_which(readLines(fileName), fixed("Coupland M"))) > 0) { print(fileName)}
}
for (fileName in fileNames) {
if (length(stringr::str_which(readLines(fileName), fixed("Coupland-M"))) > 0) { print(fileName)}
}
library(aRtsy)
library(generativeart)
library(flametree)
library(jasmines)
library(mathart)
devtools::install_github("marcusvolz/mathart")
mollusc()
library(mathart)
mollusc()
use_seed(1) %>%
entity_circle(grain = 1000) %>%
unfold_tempest(iterations = 10) %>%
style_ribbon(background = "wheat")
flametree_grow(seed = 2, trees = 3) %>%
flametree_plot(style = "voronoi")
flametree_grow(seed = 84, trees = 8) %>%
flametree_plot(style = "voronoi")
canvas_collatz(colors = '#000000', background = '#fafafa', n = 200,
angle.even = 0.0075, angle.odd = 0.0145, side = FALSE)
canvas_collatz(colors = '#32cd32', background = '#ff2305', n = 40,
angle.even = 0.0075, angle.odd = 0.0145, side = TRUE)
canvas_collatz(colors = '#ff2305', background = '#b2b2b2', n = 40,
angle.even = 0.0075, angle.odd = 0.0145, side = TRUE)
canvas_segments(colors = 'black', background = '#f09d38', n = 100, p = 0.5, H = 0.1)
canvas_collatz(colors = '#ff2305', background = '#b2b2b2', n = 40,
angle.even = 0.0075, angle.odd = 0.0145, side = TRUE)
canvas_segments(colors = '32cd32', background = '#f09d38', n = 100, p = 0.5, H = 0.1)
canvas_segments(colors = c('32cd32','ff2305','b2b2b2'), background = '#f09d38', n = 100, p = 0.5, H = 0.1)
canvas_segments(colors = c('32cd32','red','b2b2b2'), background = '#f09d38', n = 100, p = 0.5, H = 0.1)
canvas_segments(colors = c('32cd32','red','grey'), background = '#f09d38', n = 100, p = 0.5, H = 0.1)
canvas_segments(colors = c('blue','red','grey'), background = '#f09d38', n = 100, p = 0.5, H = 0.1)
set.seed(18)
canvas_segments(colors = c('blue','red','grey'), background = '#f09d38', n = 1000, p = 0.5, H = 0.1)
canvas_segments(colors = dark1, background = '#f09d38', n = 1000, p = 0.5, H = 0.1)
canvas_segments(colors = c(dark1), background = '#f09d38', n = 1000, p = 0.5, H = 0.1)
canvas_segments(colors = colorPalette(dark1), background = '#f09d38', n = 1000, p = 0.5, H = 0.1)
colorPalette(dark1)
colorPalette('dark1')
canvas_segments(colors = colorPalette('dark1'), background = '#f09d38', n = 1000, p = 0.5, H = 0.1)
#the below is red, blue, orange, grey, green.  fcfcfb is off quite
pal <- c('#ff2305','#32cd32','#f09d38','#b2b2b2','#09D36A')
canvas_segments(colors = colorPalette('pal'), background = '#fcfcfb', n = 1000, p = 0.5, H = 0.1)
pal
canvas_segments(colors = c('pal'), background = '#fcfcfb', n = 1000, p = 0.5, H = 0.1)
canvas_segments(colors = unlist('pal'), background = '#fcfcfb', n = 1000, p = 0.5, H = 0.1)
??palette_manual
#the below is red, blue, orange, grey, green.  fcfcfb is off quite
pal <- jasmintes::palette_manual('#ff2305','#32cd32','#f09d38','#b2b2b2','#09D36A')
#the below is red, blue, orange, grey, green.  fcfcfb is off quite
pal <- jasmines::palette_manual('#ff2305','#32cd32','#f09d38','#b2b2b2','#09D36A')
canvas_segments(colors = colorPalette('pal'), background = '#fcfcfb', n = 1000, p = 0.5, H = 0.1)
pal
dark1
colors()
canvas_segments(colors = c('#ff2305','#32cd32','#f09d38','#b2b2b2','#09D36A'), background = '#fcfcfb', n = 1000, p = 0.5, H = 0.1)
set.seed(18)
canvas_segments(colors = c('#ff2305','#32cd32','#f09d38','#b2b2b2','#09D36A','#0f4beb','#0d41d1'), background = '#fcfcfb', n = 1000, p = 0.5, H = 0.1)
canvas_squares(colors = c('#ff2305','#32cd32','#f09d38','#b2b2b2','#0f4beb','#0d41d1'),
cuts = 50, ratio = 1.618, width = 100, height = 100)
canvas_squares(colors = c('#ff2305','#32cd32','#f09d38','#b2b2b2','#0f4beb','#0d41d1'),
cuts = 50, ratio = 7, width = 100, height = 100)
canvas_squares(colors = c('#ff2305','#32cd32','#f09d38','#b2b2b2','#0f4beb','#0d41d1'),
cuts = 50, ratio = 1.18, width = 100, height = 100)
canvas_squares(colors = c('#ff2305','#32cd32','#f09d38','#b2b2b2','#0f4beb','#0d41d1'),
cuts = 50, ratio = 1.01, width = 100, height = 100)
canvas_squares(colors = c('#ff2305','#32cd32','#f09d38','#b2b2b2','#0f4beb','#0d41d1'),
cuts = 50, ratio = 1.05, width = 100, height = 100)
canvas_squares(colors = c('#ff2305','#32cd32','#f09d38','#b2b2b2','#0f4beb','#0d41d1'),
cuts = 100, ratio = 1.05, width = 100, height = 100)
canvas_squares(colors = c('#ff2305','#32cd32','#f09d38','#b2b2b2','#0f4beb','#0d41d1'),
cuts = 1000, ratio = 1.05, width = 100, height = 100)
set.seed(6)
canvas_squares(colors = c('#ff2305','#32cd32','#f09d38','#b2b2b2','#0f4beb','#0d41d1'),
cuts = 1000, ratio = 1.05, width = 100, height = 100)
canvas_squares(colors = c('#ff2305','#32cd32','#f09d38','#b2b2b2','#0f4beb','#0d41d1'),
cuts = 1000, ratio = 0.05, width = 100, height = 100)
canvas_squares(colors = c('#ff2305','#32cd32','#f09d38','#b2b2b2','#0f4beb','#0d41d1'),
cuts = 1000, ratio = 1.005, width = 100, height = 100)
canvas_squares(colors = c('#ff2305','#32cd32','#f09d38','#b2b2b2','#0f4beb','#0d41d1'),
cuts = 1000, ratio = 1.005, width = 10, height = 100)
canvas_squares(colors = c('#ff2305','#f09d38','#b2b2b2','#0f4beb','#0d41d1'),
cuts = 1000, ratio = 1.005, width = 100, height = 100)
canvas_squares(colors = c('#ff2305','#f09d38','#b2b2b2','#0f4beb'),
cuts = 1000, ratio = 1.005, width = 100, height = 100)
canvas_squares(colors = c('#ff2305','#b2b2b2','#0f4beb'),
cuts = 1000, ratio = 1.005, width = 100, height = 100)
canvas_squares(colors = c('#ff2305','#b2b2b2','#0f4beb'),
cuts = 1000, ratio = 1.005, width = 100, height = 100)
canvas_squares(colors = c('#ff2305','#b2b2b2','#0f4beb'),
cuts = 1000, ratio = 1.005, width = 100, height = 100)
canvas_squares(colors = c('#ff2305','#b2b2b2','#0f4beb'),
cuts = 1000, ratio = 1.005, width = 100, height = 100)
canvas_squares(colors = c('#ff2305','#b2b2b2','#0f4beb'),
cuts = 1000, ratio = 1.005, width = 100, height = 100)
canvas_squares(colors = c('#ff2305','#b2b2b2','#0f4beb'),
cuts = 1000, ratio = 1.15, width = 100, height = 100)
canvas_squares(colors = c('#ff2305','#b2b2b2','#0f4beb'),
cuts = 1000, ratio = 1.15, width = 100, height = 100)
canvas_squares(colors = c('#ff2305','#b2b2b2','#0f4beb'),
cuts = 1000, ratio = 1.15, width = 100, height = 100)
canvas_squares(colors = c('#ff2305','#b2b2b2','#0f4beb'),
cuts = 1000, ratio = 1.15, width = 100, height = 100)
canvas_squares(colors = c('#ff2305','#b2b2b2','#0f4beb'),
cuts = 1000, ratio = 1.15, width = 100, height = 100)
canvas_squares(colors = c('#ff2305','#b2b2b2','#0f4beb'),
cuts = 1000, ratio = 1.15, width = 100, height = 100)
canvas_squares(colors = c('#ff2305','#b2b2b2','#0f4beb'),
cuts = 1000, ratio = 1.15, width = 100, height = 100)
canvas_squares(colors = c('#ff2305','#b2b2b2','#0f4beb'),
cuts = 1000, ratio = 1.15, width = 100, height = 100)
canvas_squares(colors = c('#ff2305','#b2b2b2','#0f4beb'),
cuts = 1000, ratio = 1.95, width = 100, height = 100)
canvas_squares(colors = c('#ff2305','#b2b2b2','#0f4beb'),
cuts = 1000, ratio = 1.95, width = 100, height = 100)
canvas_squares(colors = c('#ff2305','#b2b2b2','#0f4beb'),
cuts = 1000, ratio = 1.95, width = 100, height = 100)
canvas_squares(colors = c('#ff2305','#b2b2b2','#0f4beb'),
cuts = 1000, ratio = 1.95, width = 100, height = 100)
canvas_squares(colors = c('#ff2305','#b2b2b2','#0f4beb'),
cuts = 1000, ratio = 1.95, width = 100, height = 100)
canvas_squares(colors = c('#ff2305','#b2b2b2','#0f4beb'),
cuts = 1000, ratio = 1.000095, width = 100, height = 100)
canvas_squares(colors = c('#ff2305','#b2b2b2','#0f4beb'),
cuts = 1000, ratio = 1.000095, width = 100, height = 100)
canvas_squares(colors = c('#ff2305','#b2b2b2','#0f4beb'),
cuts = 1000, ratio = 1.1, width = 100, height = 100)
canvas_squares(colors = c('#ff2305','#b2b2b2','#0f4beb'),
cuts = 1000, ratio = 1.1, width = 100, height = 100)
canvas_squares(colors = c('#ff2305','#b2b2b2','#0f4beb'),
cuts = 1, ratio = 1.1, width = 100, height = 100)
canvas_squares(colors = c('#ff2305','#b2b2b2','#0f4beb'),
cuts = 2, ratio = 1.1, width = 100, height = 100)
canvas_squares(colors = c('#ff2305','#b2b2b2','#0f4beb'),
cuts = 2, ratio = 1.1, width = 100, height = 100)
canvas_squares(colors = c('#ff2305','#b2b2b2','#0f4beb'),
cuts = 10000000, ratio = 1.1, width = 100, height = 100)
