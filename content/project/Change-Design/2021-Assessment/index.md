---
title: Technologies for 21st Century Self-and-Peer-Assessment (REVIEW)

subtitle: 

#If you want the summary to be something other than the first paragraph, put one in here. 
summary:

#show the date for the page, set show_date to false to hide this
date: 2021-08-03

draft: false
featured: true

#true by default
show_date:

#wont show in lists if set to true
draft: false

#can be used to highlight content in various places
featured: true

# Featured image
# To use, place an image named `featured.jpg/png` in your page's folder.
# Placement options: 1 = Full column width, 2 = Out-set, 3 = Screen-width
# Focal point options: Smart, Center, TopLeft, Top, TopRight, Left, Right, BottomLeft, Bottom, BottomRight
# Set `preview_only` to `true` to just use the image for thumbnails.
image:
  filename: featured
  placement: 1
  caption: ""
  focal_point: "Smart"
  preview_only: true
  alt_text: "REVIEW logo"

#if the page is a link to another page use this (generally use the links below instead)
external_link: 

links:
  - icon_pack: fas
    icon: arrow-alt-circle-left
    name: View all our research
    url: '/research'
  - icon_pack: fas
    icon: eye
    name: More on project site
    url: 'https://lx.uts.edu.au/blog/2021/03/03/on-track-employability-workforce-transition/'

#add authors itll auto link to ones with profiles. Use comma separated in squares like this
#you can also add partner organisations here (give them that role in the author page)
#and UTS-collaborators external-collaborators industry-collaborators (same thing)
authors: ["Darrall Thompson", "Simon Knight", "Jane Hunter"]

#add categories from options: news, illustrations, learn, resources, methods
#to create a method page create a tag first and then add the category method to the tag
categories: 
  - 

#add tags you can use like categories or like authors. Tags might cover
#technology, including: learning-analytics, mobile-technologies, 
#country or region, including: 
#sector, including: HE, schools, industry, GLAM, lifelong-learning 
#pedagogy and practice, including: sociocultural-theory, dialogic-learning, CSCL, active-learning, reflection
#content, including: recognition, funding, 
#theme which are: Change-Design, Literacies, Data-literacy, Teachers
tags:
  - Change-Design
  - assessment
  - self-and-peer-assessment
  - 21st-century-learning
  - schools
  - HE
  - reflection
  - tools

---

A significant body of centre research has focused on developing assessment strategies that support learning.  These approaches have included:

1. Development of the REVIEW software for self-assessment
1. Creation of learning analytics tools, particularly focused on 'professional reflection' to support professional development
1. Analysis of 'benchmarking' tasks and use of exemplars to support learning (you can read more about this project [here](http://sjgknight.com/finding-knowledge/2019/02/new-output-calibrating-assessment-literacy-through-benchmarking-tasks/) )
1. Designing approaches to assessing 21st century competencies, and holistic assessment for university entry (see [Darral's UTS Social Impact case study](https://socialimpact.uts.edu.au/case-study/testing-times-ensuring-ppes-effectiveness-in-low-income-countries-copy/) )

The idea of building up student's 'evaluative judgement' is common across these, and described in a bit more detail below. 

### REVIEW: Developing evaluative judgement

Single-mark or grade indicators are commonplace in describing student performance, leading to a tendency for both students and staff to focus on this single indicator, rather than more nuanced evaluation of a student’ knowledge and attributes (Thompson, 2006). Moreover, such assessments cannot provide feedback regarding the development of knowledge and other attributes across disciplinary boundaries and years of study.

The REVIEW software is an assessment tool designed to bring both summative and formative feedback together, over time, and across disciplinary boundaries. The tool has been developed to enhance learning through three modes of action:

1. Providing a self-assessment space, to encourage students to reflect on and articulate their perception of their own achievements, which they can compare to tutor-assessments that target written formative feedback at the criteria in which there is the largest gap between the self-assessment and tutor-assessment.
1. To make explicit the association between: assessments (including exams); graduate attributes; the marks given; and specific feedback (such that two identical ‘grades’ can be composed from multiple different criterion-level assessments).
1. Through ‘2’, to act as a change agent in developing and shifting assessment tasks and criteria towards constructive alignment between individual assessments – perhaps most notably examinations – and higher level graduate attributes.

Led by researchers at the University of Technology Sydney (UTS), the tool has been evaluated against these objectives over a period of 12 years. Early evaluations (Kamvounias & Thompson, 2008; Taylor et al., 2009; Thompson, Treleaven, Kamvounias, Beem, & Hill, 2008) indicated that (1) based on student feedback surveys, they had generally positive experiences in using the tool, specifically that it enhanced the clarity of the assessment expectations, and (2) based on instructor reflections and analysis of unit outline changes, the tool was a driver for change in developing explicit assessment criteria and constructive alignment between assessments and graduate attributes.

Perhaps most significantly, based on 4 semesters of REVIEW self-assessment data, analysis indicates enhancement of student learning through calibration of their self-assessments such that they become more aligned with tutor-judgements over the semesters (Boud, Lawson, & Thompson, 2013), a finding replicated over a shorter period, with varied cohorts, elsewhere (Carroll, 2013). In addition, “There are early signs in student feedback that the visual display of criteria linked to attribute categories and sub-categories is useful in charting progress and presenting to employers in interview contexts. Employers take these charts seriously because they are derived from actual official assessment criteria from a broad range of subjects over time” (Thompson, Forthcoming, p. 19)

### Video introduction to REVIEW

Watch Darrall talk about the REVIEW platform for a 'highly commended' ACODE-Pearson 2016 award.

{{< youtube ufJ55Wgh2YI >}}

Read more about Darrall's work at his author profile. 

